{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>__MÉTODOS NUMÉRICOS__</center>\n",
    "## <center>__PROJETO DA UNIDADE 2__</center>\n",
    "\n",
    "#### <center> ALUNO: Josenildo Simão da Silva </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "1. INTRODUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tema refere-se a predição sobre dados referente a pacientes com diabetes. Pretende-se descobrir a progressão da doênça com base em dados catalogados.\n",
    "Para a predição é utilizado diversas técnicas para ótimização: adição de polinômios até recursos de nosso algortimos para otimização do tempo de processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "2. DESCRIÇÃO DO PROBLEMA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo do trabalho é prever a propagação do diabetes utilizando regressão linear. Para métricas será utilizado a média de erro absoluto e a media de erro quadrático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "3. MÉTODOS APLICADOS À SOLUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solução do problema é utilizado a regressão linear.\n",
    "A regressão é  algoritmo supervisionado de machine learning utilizado para predição de dados. Aprendizagem supervisionada é a tarefa de encontrar uma função a partir de dados de treinamento rotulados. O objetivo é encontrar os melhores parâmetros  que ajustem um modelo que possa prever rótulos desconhecidos em outros objetos (o conjunto de teste) de mesma natureza. Se o rótulo é um número real, a tarefa chama-se regressão.\n",
    "regressão linear é uma equação para se estimar a condicional (valor esperado) de uma variável y, dados os valores de algumas outras variáveis x. A regressão linear é chamada \"linear\" porque se considera que a relação da resposta às variáveis é uma função linear de alguns parâmetros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "4. IMPLEMENTAÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui você irá  mostrar sua implementação para o problema considerado, explicando o que foi feito em cada passo e cada saída de cada trecho de código, sempre relacionando com a descrição do método mostrada acima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiramente vamos importar as bibliotecas  necessárias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca que implementa o conjuntos de funções  relacionados a Machine Learning e regressão linear é a sklearn.\n",
    "Segue as funções para o data set (datasets), modelo de regressão linear (linear_model), divisão dos conjuntos de dados(train_test_split), para adicionar recursos polinomiais (PolynomialFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math, scipy, numpy as np\n",
    "from scipy import linalg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo segue o conjunto  com 442 amostras com 10 variaveis independentes referente a pacientes com diabetes. As variáveis citas são a respeito características físiologicas dos pacientes. Há uma variável dependente com um valor por linha de dados quantitativo, mensurando o valor da propação da doença tomando como base a valor por linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo contém as variáveis independentes que referece-se a dados fisiológicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo é feita uma separação de dados em conjuntos de dados de treino e de teste. data.data contém os dados referentes aos variáveis independentes, já data.target com os dados refente a variável independente\n",
    "Vale atentar para o parâmetro test_size=0.2 que informa a função que 20% do conjunto de dados é testinado a dados de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn,test,y_trn,y_test = train_test_split(data.data, data.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos observar a divisão do conjuntos de dados. Vale atentar de que 20% de 442 é 88.4, como a função arredoda a divisão para mais, foi destinado 89 linhas de dados para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (89, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo é criado um modelo de regressão linear e posteriormente é treinado e é feito o cálculo do tempo do treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973 µs ± 67.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "%timeit regr.fit(trn, y_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o modelo treinado, abaixo é feita a predição dos dados em que utilizamos os método predict passando o dados que desejamos prever, como argumento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar o quão eficiente é o modelo é criado abaixo uma função cálcula duas métricas de error: erro médio absoluto e erro médio quadrático. \n",
    "O primeiro parâmetro da função referece aos valores da variável independente o segundo os resultados da predição dos dados. Espera-se que os valores da previsão sejam os mais próximos possível das valores da variável independente, ou seja, que o erro seja próximo de nulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_metrics(act, pred):\n",
    "    return (math.sqrt(metrics.mean_squared_error(act, pred)), \n",
    "     metrics.mean_absolute_error(act, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que o erro em ambas as métricas estão elevados, assim necessitando de aprimorar melhorar o conjunto de dados ou buscar uma outra maneira para que modelo seja treinado de maneira mais eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.5966412604828, 41.505239660092094)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_metrics(y_test, regr.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma opção interessante é alterar o conjunto de dados adicionando recursos polinomiais, eles alteram o grau do conjunto de dados adicionando um coluna a cada varíável existente, contendo o valor do alterando das repesctivas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A baixo é feita a transformação das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_feat = poly.fit_transform(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que cada variável tinha grau linear, após a tranformação passaram a conter colunas adicionais com valores de grau quadrático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age, sex, bmi, bp, s1, s2, s3, s4, s5, s6, age^2, age sex, age bmi, age bp, age s1, age s2, age s3, age s4, age s5, age s6, sex^2, sex bmi, sex bp, sex s1, sex s2, sex s3, sex s4, sex s5, sex s6, bmi^2, bmi bp, bmi s1, bmi s2, bmi s3, bmi s4, bmi s5, bmi s6, bp^2, bp s1, bp s2, bp s3, bp s4, bp s5, bp s6, s1^2, s1 s2, s1 s3, s1 s4, s1 s5, s1 s6, s2^2, s2 s3, s2 s4, s2 s5, s2 s6, s3^2, s3 s4, s3 s5, s3 s6, s4^2, s4 s5, s4 s6, s5^2, s5 s6, s6^2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(poly.get_feature_names(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A baixo o modelo é treinado com o dada set  modificados(trn_feat) e posteriormente feito a medição de enficiencias em termos de acertividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.95088736836648, 45.34613836524468)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(trn_feat, y_trn)\n",
    "regr_metrics(y_test, regr.predict(poly.fit_transform(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas agora termos outro problema: nossa solução ficou pouco lenta, está quadrática em rescursos ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635 µs ± 23 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit poly.fit_transform(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver esse problema podemos utilizar o Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math, scipy, numpy as np\n",
    "from scipy import linalg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse data set é a respeito do diagnóstico com nódulos mamários que pode representar cancer de mama. Onde é especificado diversas variáveis independentes com especifícações físiologicas do tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame (data.data, columns = data.feature_names)\n",
    "df ['target'] = data.target\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(data.data,data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7 ms ± 86.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "%timeit regr.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_metrics(act, pred):\n",
    "    return (math.sqrt(metrics.mean_squared_error(act, pred)), \n",
    "     metrics.mean_absolute_error(act, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25119838546853623, 0.19883336421133496)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_metrics(y_test, regr.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_feat = poly.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean radius, mean texture, mean perimeter, mean area, mean smoothness, mean compactness, mean concavity, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst radius, worst texture, worst perimeter, worst area, worst smoothness, worst compactness, worst concavity, worst concave points, worst symmetry, worst fractal dimension, mean radius^2, mean radius mean texture, mean radius mean perimeter, mean radius mean area, mean radius mean smoothness, mean radius mean compactness, mean radius mean concavity, mean radius mean concave points, mean radius mean symmetry, mean radius mean fractal dimension, mean radius radius error, mean radius texture error, mean radius perimeter error, mean radius area error, mean radius smoothness error, mean radius compactness error, mean radius concavity error, mean radius concave points error, mean radius symmetry error, mean radius fractal dimension error, mean radius worst radius, mean radius worst texture, mean radius worst perimeter, mean radius worst area, mean radius worst smoothness, mean radius worst compactness, mean radius worst concavity, mean radius worst concave points, mean radius worst symmetry, mean radius worst fractal dimension, mean texture^2, mean texture mean perimeter, mean texture mean area, mean texture mean smoothness, mean texture mean compactness, mean texture mean concavity, mean texture mean concave points, mean texture mean symmetry, mean texture mean fractal dimension, mean texture radius error, mean texture texture error, mean texture perimeter error, mean texture area error, mean texture smoothness error, mean texture compactness error, mean texture concavity error, mean texture concave points error, mean texture symmetry error, mean texture fractal dimension error, mean texture worst radius, mean texture worst texture, mean texture worst perimeter, mean texture worst area, mean texture worst smoothness, mean texture worst compactness, mean texture worst concavity, mean texture worst concave points, mean texture worst symmetry, mean texture worst fractal dimension, mean perimeter^2, mean perimeter mean area, mean perimeter mean smoothness, mean perimeter mean compactness, mean perimeter mean concavity, mean perimeter mean concave points, mean perimeter mean symmetry, mean perimeter mean fractal dimension, mean perimeter radius error, mean perimeter texture error, mean perimeter perimeter error, mean perimeter area error, mean perimeter smoothness error, mean perimeter compactness error, mean perimeter concavity error, mean perimeter concave points error, mean perimeter symmetry error, mean perimeter fractal dimension error, mean perimeter worst radius, mean perimeter worst texture, mean perimeter worst perimeter, mean perimeter worst area, mean perimeter worst smoothness, mean perimeter worst compactness, mean perimeter worst concavity, mean perimeter worst concave points, mean perimeter worst symmetry, mean perimeter worst fractal dimension, mean area^2, mean area mean smoothness, mean area mean compactness, mean area mean concavity, mean area mean concave points, mean area mean symmetry, mean area mean fractal dimension, mean area radius error, mean area texture error, mean area perimeter error, mean area area error, mean area smoothness error, mean area compactness error, mean area concavity error, mean area concave points error, mean area symmetry error, mean area fractal dimension error, mean area worst radius, mean area worst texture, mean area worst perimeter, mean area worst area, mean area worst smoothness, mean area worst compactness, mean area worst concavity, mean area worst concave points, mean area worst symmetry, mean area worst fractal dimension, mean smoothness^2, mean smoothness mean compactness, mean smoothness mean concavity, mean smoothness mean concave points, mean smoothness mean symmetry, mean smoothness mean fractal dimension, mean smoothness radius error, mean smoothness texture error, mean smoothness perimeter error, mean smoothness area error, mean smoothness smoothness error, mean smoothness compactness error, mean smoothness concavity error, mean smoothness concave points error, mean smoothness symmetry error, mean smoothness fractal dimension error, mean smoothness worst radius, mean smoothness worst texture, mean smoothness worst perimeter, mean smoothness worst area, mean smoothness worst smoothness, mean smoothness worst compactness, mean smoothness worst concavity, mean smoothness worst concave points, mean smoothness worst symmetry, mean smoothness worst fractal dimension, mean compactness^2, mean compactness mean concavity, mean compactness mean concave points, mean compactness mean symmetry, mean compactness mean fractal dimension, mean compactness radius error, mean compactness texture error, mean compactness perimeter error, mean compactness area error, mean compactness smoothness error, mean compactness compactness error, mean compactness concavity error, mean compactness concave points error, mean compactness symmetry error, mean compactness fractal dimension error, mean compactness worst radius, mean compactness worst texture, mean compactness worst perimeter, mean compactness worst area, mean compactness worst smoothness, mean compactness worst compactness, mean compactness worst concavity, mean compactness worst concave points, mean compactness worst symmetry, mean compactness worst fractal dimension, mean concavity^2, mean concavity mean concave points, mean concavity mean symmetry, mean concavity mean fractal dimension, mean concavity radius error, mean concavity texture error, mean concavity perimeter error, mean concavity area error, mean concavity smoothness error, mean concavity compactness error, mean concavity concavity error, mean concavity concave points error, mean concavity symmetry error, mean concavity fractal dimension error, mean concavity worst radius, mean concavity worst texture, mean concavity worst perimeter, mean concavity worst area, mean concavity worst smoothness, mean concavity worst compactness, mean concavity worst concavity, mean concavity worst concave points, mean concavity worst symmetry, mean concavity worst fractal dimension, mean concave points^2, mean concave points mean symmetry, mean concave points mean fractal dimension, mean concave points radius error, mean concave points texture error, mean concave points perimeter error, mean concave points area error, mean concave points smoothness error, mean concave points compactness error, mean concave points concavity error, mean concave points concave points error, mean concave points symmetry error, mean concave points fractal dimension error, mean concave points worst radius, mean concave points worst texture, mean concave points worst perimeter, mean concave points worst area, mean concave points worst smoothness, mean concave points worst compactness, mean concave points worst concavity, mean concave points worst concave points, mean concave points worst symmetry, mean concave points worst fractal dimension, mean symmetry^2, mean symmetry mean fractal dimension, mean symmetry radius error, mean symmetry texture error, mean symmetry perimeter error, mean symmetry area error, mean symmetry smoothness error, mean symmetry compactness error, mean symmetry concavity error, mean symmetry concave points error, mean symmetry symmetry error, mean symmetry fractal dimension error, mean symmetry worst radius, mean symmetry worst texture, mean symmetry worst perimeter, mean symmetry worst area, mean symmetry worst smoothness, mean symmetry worst compactness, mean symmetry worst concavity, mean symmetry worst concave points, mean symmetry worst symmetry, mean symmetry worst fractal dimension, mean fractal dimension^2, mean fractal dimension radius error, mean fractal dimension texture error, mean fractal dimension perimeter error, mean fractal dimension area error, mean fractal dimension smoothness error, mean fractal dimension compactness error, mean fractal dimension concavity error, mean fractal dimension concave points error, mean fractal dimension symmetry error, mean fractal dimension fractal dimension error, mean fractal dimension worst radius, mean fractal dimension worst texture, mean fractal dimension worst perimeter, mean fractal dimension worst area, mean fractal dimension worst smoothness, mean fractal dimension worst compactness, mean fractal dimension worst concavity, mean fractal dimension worst concave points, mean fractal dimension worst symmetry, mean fractal dimension worst fractal dimension, radius error^2, radius error texture error, radius error perimeter error, radius error area error, radius error smoothness error, radius error compactness error, radius error concavity error, radius error concave points error, radius error symmetry error, radius error fractal dimension error, radius error worst radius, radius error worst texture, radius error worst perimeter, radius error worst area, radius error worst smoothness, radius error worst compactness, radius error worst concavity, radius error worst concave points, radius error worst symmetry, radius error worst fractal dimension, texture error^2, texture error perimeter error, texture error area error, texture error smoothness error, texture error compactness error, texture error concavity error, texture error concave points error, texture error symmetry error, texture error fractal dimension error, texture error worst radius, texture error worst texture, texture error worst perimeter, texture error worst area, texture error worst smoothness, texture error worst compactness, texture error worst concavity, texture error worst concave points, texture error worst symmetry, texture error worst fractal dimension, perimeter error^2, perimeter error area error, perimeter error smoothness error, perimeter error compactness error, perimeter error concavity error, perimeter error concave points error, perimeter error symmetry error, perimeter error fractal dimension error, perimeter error worst radius, perimeter error worst texture, perimeter error worst perimeter, perimeter error worst area, perimeter error worst smoothness, perimeter error worst compactness, perimeter error worst concavity, perimeter error worst concave points, perimeter error worst symmetry, perimeter error worst fractal dimension, area error^2, area error smoothness error, area error compactness error, area error concavity error, area error concave points error, area error symmetry error, area error fractal dimension error, area error worst radius, area error worst texture, area error worst perimeter, area error worst area, area error worst smoothness, area error worst compactness, area error worst concavity, area error worst concave points, area error worst symmetry, area error worst fractal dimension, smoothness error^2, smoothness error compactness error, smoothness error concavity error, smoothness error concave points error, smoothness error symmetry error, smoothness error fractal dimension error, smoothness error worst radius, smoothness error worst texture, smoothness error worst perimeter, smoothness error worst area, smoothness error worst smoothness, smoothness error worst compactness, smoothness error worst concavity, smoothness error worst concave points, smoothness error worst symmetry, smoothness error worst fractal dimension, compactness error^2, compactness error concavity error, compactness error concave points error, compactness error symmetry error, compactness error fractal dimension error, compactness error worst radius, compactness error worst texture, compactness error worst perimeter, compactness error worst area, compactness error worst smoothness, compactness error worst compactness, compactness error worst concavity, compactness error worst concave points, compactness error worst symmetry, compactness error worst fractal dimension, concavity error^2, concavity error concave points error, concavity error symmetry error, concavity error fractal dimension error, concavity error worst radius, concavity error worst texture, concavity error worst perimeter, concavity error worst area, concavity error worst smoothness, concavity error worst compactness, concavity error worst concavity, concavity error worst concave points, concavity error worst symmetry, concavity error worst fractal dimension, concave points error^2, concave points error symmetry error, concave points error fractal dimension error, concave points error worst radius, concave points error worst texture, concave points error worst perimeter, concave points error worst area, concave points error worst smoothness, concave points error worst compactness, concave points error worst concavity, concave points error worst concave points, concave points error worst symmetry, concave points error worst fractal dimension, symmetry error^2, symmetry error fractal dimension error, symmetry error worst radius, symmetry error worst texture, symmetry error worst perimeter, symmetry error worst area, symmetry error worst smoothness, symmetry error worst compactness, symmetry error worst concavity, symmetry error worst concave points, symmetry error worst symmetry, symmetry error worst fractal dimension, fractal dimension error^2, fractal dimension error worst radius, fractal dimension error worst texture, fractal dimension error worst perimeter, fractal dimension error worst area, fractal dimension error worst smoothness, fractal dimension error worst compactness, fractal dimension error worst concavity, fractal dimension error worst concave points, fractal dimension error worst symmetry, fractal dimension error worst fractal dimension, worst radius^2, worst radius worst texture, worst radius worst perimeter, worst radius worst area, worst radius worst smoothness, worst radius worst compactness, worst radius worst concavity, worst radius worst concave points, worst radius worst symmetry, worst radius worst fractal dimension, worst texture^2, worst texture worst perimeter, worst texture worst area, worst texture worst smoothness, worst texture worst compactness, worst texture worst concavity, worst texture worst concave points, worst texture worst symmetry, worst texture worst fractal dimension, worst perimeter^2, worst perimeter worst area, worst perimeter worst smoothness, worst perimeter worst compactness, worst perimeter worst concavity, worst perimeter worst concave points, worst perimeter worst symmetry, worst perimeter worst fractal dimension, worst area^2, worst area worst smoothness, worst area worst compactness, worst area worst concavity, worst area worst concave points, worst area worst symmetry, worst area worst fractal dimension, worst smoothness^2, worst smoothness worst compactness, worst smoothness worst concavity, worst smoothness worst concave points, worst smoothness worst symmetry, worst smoothness worst fractal dimension, worst compactness^2, worst compactness worst concavity, worst compactness worst concave points, worst compactness worst symmetry, worst compactness worst fractal dimension, worst concavity^2, worst concavity worst concave points, worst concavity worst symmetry, worst concavity worst fractal dimension, worst concave points^2, worst concave points worst symmetry, worst concave points worst fractal dimension, worst symmetry^2, worst symmetry worst fractal dimension, worst fractal dimension^2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(poly.get_feature_names(data.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(trn_feat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47.51334692829148, 5.538121894530973)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_metrics(y_test, regr.predict(poly.fit_transform(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94 ms ± 63.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit poly.fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhorar o desepenho podemos usar o numba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
